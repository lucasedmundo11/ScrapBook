# ScrapBook API

Uma API RESTful completa para web scraping de livros com foco em Machine Learning Engineering. Este projeto extrai dados de livros do site [books.toscrape.com](http://books.toscrape.com/) e disponibiliza atravÃ©s de uma API robusta construÃ­da com Flask e SQLAlchemy.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Funcionalidades](#funcionalidades)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [ExecuÃ§Ã£o](#execuÃ§Ã£o)
- [DocumentaÃ§Ã£o da API](#documentaÃ§Ã£o-da-api)
- [Endpoints](#endpoints)
- [Exemplos de Uso](#exemplos-de-uso)
- [AutenticaÃ§Ã£o](#autenticaÃ§Ã£o)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)

## ğŸš€ VisÃ£o Geral

O ScrapBook API Ã© um sistema completo de web scraping e anÃ¡lise de dados de livros, projetado com as melhores prÃ¡ticas de Machine Learning Engineering. O projeto inclui:

- **Web Scraping Robusto**: Sistema de extraÃ§Ã£o de dados com retry logic e rate limiting
- **API RESTful Completa**: 20+ endpoints para gerenciamento de dados
- **AutenticaÃ§Ã£o JWT**: Sistema seguro de autenticaÃ§Ã£o e autorizaÃ§Ã£o
- **DocumentaÃ§Ã£o Swagger**: Interface interativa para explorar a API
- **Gerenciamento de UsuÃ¡rios**: Sistema completo de CRUD para usuÃ¡rios
- **Pipeline de ML**: Endpoints especÃ­ficos para features de Machine Learning
- **Monitoramento**: Sistema de logs estruturados e mÃ©tricas

## ğŸ—ï¸ Arquitetura

```
ScrapBook/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # API Flask com endpoints RESTful
â”‚   â”œâ”€â”€ scripts/          # Sistema de web scraping
â”‚   â”œâ”€â”€ config/           # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ csv/              # Dados extraÃ­dos em CSV
â”‚   â”œâ”€â”€ json/             # Dados em formato JSON
â”‚   â””â”€â”€ logs/             # Logs do sistema
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ resources/        # DocumentaÃ§Ã£o de Funcionalidades e Requisitos Funcionais
â”‚   â””â”€â”€ swagger/          # DocumentaÃ§Ã£o Swagger YAML
â””â”€â”€ tests/                # Testes automatizados
```

### Componentes Principais

1. **Web Scraper**: Sistema baseado em BeautifulSoup para extraÃ§Ã£o de dados
2. **API REST**: Flask + SQLAlchemy para endpoints RESTful
3. **Banco de Dados**: SQLAlchemy com suporte a SQLite/PostgreSQL
4. **AutenticaÃ§Ã£o**: JWT com Flask-JWT-Extended
5. **DocumentaÃ§Ã£o**: Swagger/OpenAPI com Flasgger

## âœ¨ Funcionalidades

### Core Features
- âœ… Listagem paginada de livros
- âœ… Busca avanÃ§ada por tÃ­tulo, categoria, preÃ§o e rating
- âœ… EstatÃ­sticas e insights dos dados
- âœ… Filtros por faixa de preÃ§o
- âœ… Top livros mais bem avaliados

### Sistema de UsuÃ¡rios
- âœ… Registro e login de usuÃ¡rios
- âœ… Gerenciamento completo de usuÃ¡rios (CRUD)
- âœ… Controle de acesso baseado em roles (admin/user)
- âœ… AlteraÃ§Ã£o de senha segura

### Web Scraping
- âœ… ExecuÃ§Ã£o manual de scraping via API
- âœ… Monitoramento de jobs de scraping
- âœ… HistÃ³rico de execuÃ§Ãµes
- âœ… Rate limiting e retry logic

### Machine Learning
- âœ… Endpoints para features engineering
- âœ… Datasets formatados para treinamento
- âœ… Interface para prediÃ§Ãµes de modelos

## ğŸ”§ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.11+
- pip
- virtualenv (recomendado)

### Passo a Passo

1. **Clone o repositÃ³rio**
```bash
git clone <repository-url>
cd ScrapBook
```

2. **Crie e ative o ambiente virtual**
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure as variÃ¡veis de ambiente**
```bash
cp .env.example .env  # Se disponÃ­vel
# ou crie um arquivo .env com as configuraÃ§Ãµes necessÃ¡rias
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```env
# API Settings
API_HOST=localhost
API_PORT=8000

# JWT Configuration
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# Database
DATABASE_URL=sqlite:///./data/books.db

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# CORS
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
```

### ConfiguraÃ§Ã£o do Banco de Dados

O sistema criarÃ¡ automaticamente:
- Banco de dados SQLite em `data/books.db`
- UsuÃ¡rio admin padrÃ£o: `admin`/`admin123`
- UsuÃ¡rio comum padrÃ£o: `user`/`user123`

## ğŸš€ ExecuÃ§Ã£o

### Iniciar a API

```bash
# MÃ©todo 1: Via mÃ³dulo
python -m src.api.main

# MÃ©todo 2: Executar diretamente
cd src/api && python main.py

# MÃ©todo 3: Com script personalizado (se disponÃ­vel)
./start_api.sh
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`

### Acessar DocumentaÃ§Ã£o

- **Swagger UI**: http://localhost:8000/docs
- **API Spec**: http://localhost:8000/apispec.json
- **Health Check**: http://localhost:8000/api/v1/health

## ğŸ“š DocumentaÃ§Ã£o da API

### Base URL
```
http://localhost:8000/api/v1
```

### AutenticaÃ§Ã£o
A API usa JWT Bearer tokens. Para endpoints protegidos, inclua o header:
```
Authorization: Bearer <seu-jwt-token>
```

### Response Format
Todas as respostas seguem o padrÃ£o:

```json
{
  "success": true,
  "data": { ... },
  "message": "Success message",
  "timestamp": "2025-08-10T10:30:00Z"
}
```

Para erros:
```json
{
  "success": false,
  "error": {
    "code": "ERROR_CODE",
    "message": "Error description",
    "details": { ... }
  },
  "timestamp": "2025-08-10T10:30:00Z"
}
```

## ğŸ›£ï¸ Endpoints

### ğŸ” Core Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `GET` | `/health` | Status da API | âŒ |
| `GET` | `/books` | Lista todos os livros | âŒ |
| `GET` | `/books/{id}` | Detalhes de um livro | âŒ |
| `GET` | `/books/search` | Busca livros | âŒ |
| `GET` | `/categories` | Lista categorias | âŒ |

### ğŸ“Š Endpoints de Insights

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `GET` | `/stats/overview` | EstatÃ­sticas gerais | âŒ |
| `GET` | `/stats/categories` | Stats por categoria | âŒ |
| `GET` | `/books/top-rated` | Top livros avaliados | âŒ |
| `GET` | `/books/price-range` | Filtro por preÃ§o | âŒ |

### ğŸ” AutenticaÃ§Ã£o

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `POST` | `/auth/login` | Login do usuÃ¡rio | âŒ |
| `POST` | `/auth/refresh` | Renovar token | âŒ |

### ğŸ‘¥ Gerenciamento de UsuÃ¡rios

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `GET` | `/users` | Listar usuÃ¡rios | âœ… Admin |
| `POST` | `/users` | Criar usuÃ¡rio | âœ… Admin |
| `PUT` | `/users/{id}` | Atualizar usuÃ¡rio | âœ… Admin/Own |
| `PUT` | `/users/{id}/password` | Alterar senha | âœ… Admin/Own |
| `GET` | `/users/me` | Perfil atual | âœ… |

### ğŸ¤– Machine Learning

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `GET` | `/ml/features` | Features para ML | âŒ |
| `GET` | `/ml/training-data` | Dataset treinamento | âŒ |
| `POST` | `/ml/predictions` | Fazer prediÃ§Ãµes | âŒ |

### ğŸ•·ï¸ Web Scraping

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Auth |
|--------|----------|-----------|------|
| `POST` | `/scraping/trigger` | Iniciar scraping | âœ… Admin |
| `GET` | `/scraping/status/{job_id}` | Status do job | âœ… Admin |
| `GET` | `/scraping/jobs` | Listar jobs | âœ… Admin |

## ğŸ“– Exemplos de Uso

### 1. Login e ObtenÃ§Ã£o de Token

```bash
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "admin",
    "password": "admin123"
  }'
```

**Response:**
```json
{
  "success": true,
  "data": {
    "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
    "refresh_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
    "token_type": "bearer",
    "expires_in": 1800
  },
  "message": "Login successful",
  "timestamp": "2025-08-10T15:30:00Z"
}
```

### 2. Listar Livros com PaginaÃ§Ã£o

```bash
curl -X GET "http://localhost:8000/api/v1/books?page=1&limit=5&sort_by=price&sort_order=desc"
```

**Response:**
```json
{
  "success": true,
  "data": {
    "books": [
      {
        "id": 1,
        "title": "A Light in the Attic",
        "price": 51.77,
        "rating": 3,
        "availability": "In stock",
        "category": "Poetry",
        "image_url": "catalogue/images/products/51/51.jpg"
      }
    ],
    "pagination": {
      "current_page": 1,
      "total_pages": 200,
      "total_books": 1000,
      "has_next": true,
      "has_prev": false
    }
  },
  "message": "Retrieved 5 books",
  "timestamp": "2025-08-10T15:30:00Z"
}
```

### 3. Buscar Livros

```bash
curl -X GET "http://localhost:8000/api/v1/books/search?title=Light&category=Poetry&min_price=30&max_price=60"
```

### 4. Criar UsuÃ¡rio (Admin)

```bash
curl -X POST http://localhost:8000/api/v1/users \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <seu-token>" \
  -d '{
    "username": "newuser",
    "email": "user@example.com",
    "password": "password123",
    "is_admin": false
  }'
```

### 5. Executar Scraping

```bash
curl -X POST http://localhost:8000/api/v1/scraping/trigger \
  -H "Authorization: Bearer <seu-token>"
```

**Response:**
```json
{
  "success": true,
  "data": {
    "job_id": "scraping_job_20250810_153045",
    "status": "started",
    "message": "Scraping job started successfully"
  },
  "message": "Scraping process started",
  "timestamp": "2025-08-10T15:30:45Z"
}
```

### 6. Verificar Status do Scraping

```bash
curl -X GET http://localhost:8000/api/v1/scraping/status/scraping_job_20250810_153045 \
  -H "Authorization: Bearer <seu-token>"
```

### 7. Obter EstatÃ­sticas

```bash
curl -X GET http://localhost:8000/api/v1/stats/overview
```

**Response:**
```json
{
  "success": true,
  "data": {
    "total_books": 1000,
    "total_categories": 50,
    "average_price": 35.67,
    "average_rating": 3.2,
    "most_expensive_book": {
      "title": "Expensive Book",
      "price": 58.99
    },
    "cheapest_book": {
      "title": "Cheap Book", 
      "price": 10.00
    }
  },
  "message": "Overview statistics retrieved successfully",
  "timestamp": "2025-08-10T15:30:00Z"
}
```

## ğŸ” AutenticaÃ§Ã£o

### UsuÃ¡rios PadrÃ£o

O sistema vem com usuÃ¡rios prÃ©-configurados:

| Username | Password | Role | DescriÃ§Ã£o |
|----------|----------|------|-----------|
| `admin` | `admin123` | Admin | Acesso completo ao sistema |
| `user` | `user123` | User | Acesso limitado aos endpoints pÃºblicos |

### CriaÃ§Ã£o de Novos UsuÃ¡rios

Apenas administradores podem criar novos usuÃ¡rios atravÃ©s do endpoint `/users`.

### ExpiraÃ§Ã£o de Tokens

- **Access Token**: 30 minutos (configurÃ¡vel)
- **Refresh Token**: 7 dias (configurÃ¡vel)

## ğŸ—‚ï¸ Estrutura do Projeto

```
ScrapBook/
â”œâ”€â”€ .venv/                          # Ambiente virtual Python
â”œâ”€â”€ data/                           # Dados extraÃ­dos e logs
â”‚   â”œâ”€â”€ csv/                        # Arquivos CSV dos livros
â”‚   â”‚   â”œâ”€â”€ books_detailed_*.csv    # Dados detalhados dos livros
â”‚   â”‚   â””â”€â”€ categories_*.csv        # Lista de categorias
â”‚   â”œâ”€â”€ json/                       # Dados em formato JSON
â”‚   â””â”€â”€ logs/                       # Logs do sistema
â”œâ”€â”€ docs/                           # DocumentaÃ§Ã£o
â”‚   â””â”€â”€ swagger/                    # Specs Swagger YAML
â”‚       â”œâ”€â”€ auth_*.yaml            # Endpoints de autenticaÃ§Ã£o
â”‚       â”œâ”€â”€ books_*.yaml           # Endpoints de livros
â”‚       â”œâ”€â”€ users_*.yaml           # Endpoints de usuÃ¡rios
â”‚       â””â”€â”€ *.yaml                 # Outros endpoints
â”œâ”€â”€ src/                            # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ api/                        # API Flask
â”‚   â”‚   â”œâ”€â”€ main.py                # AplicaÃ§Ã£o principal
â”‚   â”‚   â”œâ”€â”€ auth.py                # Sistema de autenticaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ database.py            # Gerenciador do banco
â”‚   â”‚   â””â”€â”€ models.py              # Modelos SQLAlchemy/Pydantic
â”‚   â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ api.py                 # Config da API
â”‚   â”‚   â””â”€â”€ Scrapper.py            # Config do scraper
â”‚   â””â”€â”€ scripts/                    # Sistema de scraping
â”‚       â”œâ”€â”€ main_scraper.py        # Orquestrador principal
â”‚       â”œâ”€â”€ book_scraper.py        # Scraper de livros
â”‚       â”œâ”€â”€ category_scraper.py    # Scraper de categorias
â”‚       â””â”€â”€ utils/                 # UtilitÃ¡rios
â”œâ”€â”€ tests/                          # Testes automatizados
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ .env.example                    # Exemplo de variÃ¡veis de ambiente
â””â”€â”€ README.md                       # Este arquivo
```

## ğŸ§ª Testes

### Executar Testes

```bash
# Todos os testes
pytest

# Testes especÃ­ficos
pytest tests/test_api.py
pytest tests/test_scraper.py

# Com cobertura
pytest --cov=src tests/
```

### Health Check

Verifique se a API estÃ¡ funcionando:

```bash
curl http://localhost:8000/api/v1/health
```

## ğŸ”„ Pipeline de Dados

### Fluxo do Scraping

1. **Trigger Manual**: Via endpoint `/scraping/trigger`
2. **ExtraÃ§Ã£o**: Scraping do site books.toscrape.com
3. **Processamento**: Limpeza e validaÃ§Ã£o dos dados
4. **Armazenamento**: Salvamento em CSV e banco de dados
5. **NotificaÃ§Ã£o**: Job status disponÃ­vel via API

### Estrutura dos Dados

Os dados extraÃ­dos incluem:
- **Title**: TÃ­tulo do livro
- **Price**: PreÃ§o em GBP
- **Rating**: AvaliaÃ§Ã£o (1-5 estrelas)
- **Availability**: Status de disponibilidade
- **Category**: Categoria/gÃªnero
- **Image URL**: URL da imagem da capa
- **Description**: DescriÃ§Ã£o do livro

## ğŸ“Š Monitoramento e Logs

### Sistema de Logs

- **Structured Logging**: Logs em formato JSON
- **Diferentes NÃ­veis**: INFO, WARNING, ERROR
- **RotaÃ§Ã£o AutomÃ¡tica**: Para evitar arquivos grandes
- **LocalizaÃ§Ã£o**: `data/logs/`

### MÃ©tricas DisponÃ­veis

- Tempo de resposta dos endpoints
- NÃºmero de requisiÃ§Ãµes por minuto
- Erros e exceÃ§Ãµes
- Status dos jobs de scraping

## ğŸš€ Deploy

### Desenvolvimento Local

```bash
python -m src.api.main
```

### ProduÃ§Ã£o

O sistema estÃ¡ preparado para deploy em:
- **Heroku**
- **Render**
- **AWS**
- **Docker**

### VariÃ¡veis de Ambiente para ProduÃ§Ã£o

```env
API_HOST=0.0.0.0
API_PORT=5000
JWT_SECRET_KEY=<strong-secret-key>
DATABASE_URL=postgresql://user:pass@host:port/db
CORS_ORIGINS=https://yourdomain.com
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Suporte

- **DocumentaÃ§Ã£o**: http://localhost:8000/docs
- **Issues**: GitHub Issues
- **Email**: support@scrapbook-api.com

---

**Desenvolvido com â¤ï¸ para Machine Learning Engineering**
